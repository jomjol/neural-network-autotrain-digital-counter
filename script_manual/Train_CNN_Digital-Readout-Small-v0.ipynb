{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"dig1330s0\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.0              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 5\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1684, 32, 20, 3)\n",
      "(1684, 11)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_resize'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = base[0:1]\n",
    "    if target == \"N\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = int(target)\n",
    "    test_image = Image.open(aktfile)\n",
    "    test_image = np.array(test_image, dtype=\"float32\")\n",
    "    x_data.append(test_image)\n",
    "    y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 20, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 20, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 324,631\n",
      "Trainable params: 324,625\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "421/421 [==============================] - 3s 5ms/step - loss: 2.2638 - accuracy: 0.2750\n",
      "Epoch 2/5\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5019 - accuracy: 0.5127\n",
      "Epoch 3/5\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.9607 - accuracy: 0.6881\n",
      "Epoch 4/5\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.7306 - accuracy: 0.7546\n",
      "Epoch 5/5\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.6281 - accuracy: 0.7973\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27200/2916101208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Result'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_resize'\n",
    "res = []\n",
    "only_deviation = True\n",
    "show_wrong_image = True\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.jpg')\n",
    "\n",
    "for aktfile in files:\n",
    "    base = os.path.basename(aktfile)\n",
    "    target = base[0:1]\n",
    "    if target == \"N\":\n",
    "        zw1 = -1\n",
    "    else:\n",
    "        zw1 = int(target)\n",
    "    expected_class = zw1\n",
    "    image_in = Image.open(aktfile)\n",
    "    test_image = np.array(image_in, dtype=\"float32\")\n",
    "    img = np.reshape(test_image,[1,32,20,3])\n",
    "    classes = np.argmax(model.predict(img), axis=-1)\n",
    "    classes = classes[0]\n",
    "    if classes == 10: \n",
    "        classes = -1\n",
    "    zw2 = classes\n",
    "    zw3 = zw2 - zw1\n",
    "    res.append(np.array([zw1, zw2, zw3]))\n",
    "    if only_deviation == True:\n",
    "        if str(classes) != str(expected_class):\n",
    "            print(aktfile + \" \" + str(expected_class) +  \" \" + str(classes))\n",
    "            if show_wrong_image == True:\n",
    "                display(image_in)\n",
    "    else:\n",
    "        print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n",
    "        \n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "FileName = TFliteNamingAndVersion + \"q\" + \".tflite\"\n",
    "\n",
    "def representative_dataset():\n",
    "    for n in range(x_data[0].size):\n",
    "      data = np.expand_dims(x_data[5], axis=0)\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName, \"wb\").write(tflite_quant_model)\n",
    "print(FileName)\n",
    "Path(FileName).stat().st_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x000001D29E593670>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
